[metadata]
name = airbyte-source-stripe
version = 5.2.2
author = Airbyte
author_email = contact@airbyte.io
long_description = # Stripe Source
	
	This is the repository for the Stripe source connector, written in Python.
	For information about how to use this connector within Airbyte, see [the documentation](https://docs.airbyte.io/integrations/sources/stripe).
	
	
	**To iterate on this connector, make sure to complete this prerequisites section.**
	
	
	From this connector directory, create a virtual environment:
	```
	python -m venv .venv
	```
	
	This will generate a virtualenv for this module in `.venv/`. Make sure this venv is active in your
	development environment of choice. To activate it from the terminal, run:
	```
	source .venv/bin/activate
	pip install -r requirements.txt
	```
	If you are in an IDE, follow your IDE's instructions to activate the virtualenv.
	
	Note that while we are installing dependencies from `requirements.txt`, you should only edit `setup.py` for your dependencies. `requirements.txt` is
	used for editable installs (`pip install -e`) to pull in Python dependencies from the monorepo and will call `setup.py`.
	If this is mumbo jumbo to you, don't worry about it, just put your deps in `setup.py` but install using `pip install -r requirements.txt` and everything
	should work as you expect.
	
	**If you are a community contributor**, follow the instructions in the [documentation](https://docs.airbyte.io/integrations/sources/stripe)
	to generate the necessary credentials. Then create a file `secrets/config.json` conforming to the `source_stripe/spec.yaml` file.
	Note that any directory named `secrets` is gitignored across the entire Airbyte repo, so there is no danger of accidentally checking in sensitive information.
	See `sample_files/sample_config.json` for a sample config file.
	
	**If you are an Airbyte core member**, copy the credentials in Lastpass under the secret name `source stripe test creds`
	and place them into `secrets/config.json`.
	
	
	```
	python main.py spec
	python main.py check --config secrets/config.json
	python main.py discover --config secrets/config.json
	python main.py read --config secrets/config.json --catalog sample_files/configured_catalog.json
	```
	
	To run unit tests locally, from the connector directory run:
	```
	python -m pytest unit_tests
	```
	
	Customize `acceptance-test-config.yml` file to configure tests. See [Connector Acceptance Tests](https://docs.airbyte.io/connector-development/testing-connectors/connector-acceptance-tests-reference) for more information.
	If your connector requires to create or destroy resources for use during acceptance tests create fixtures for it and place them inside integration_tests/acceptance.py.
	To run your integration tests with acceptance tests, from the connector root, run
	```
	docker build . --no-cache -t airbyte/source-stripe:dev \
	&& python -m pytest integration_tests -p integration_tests.acceptance
	```
	
	All of your dependencies should go in `setup.py`, NOT `requirements.txt`. The requirements file is only used to connect internal Airbyte dependencies in the monorepo for local development.
	
	You've checked out the repo, implemented a million dollar feature, and you're ready to share your changes with the world. Now what?
	1. Make sure your changes are passing our test suite: `airbyte-ci connectors --name=source-stripe test`
	2. Bump the connector version in `metadata.yaml`: increment the `dockerImageTag` value. Please follow [semantic versioning for connectors](https://docs.airbyte.com/contributing-to-airbyte/resources/pull-requests-handbook/#semantic-versioning-for-connectors).
	3. Make sure the `metadata.yaml` content is up to date.
	4. Make the connector documentation and its changelog is up to date (`docs/integrations/sources/stripe.md`).
	5. Create a Pull Request: use [our PR naming conventions](https://docs.airbyte.com/contributing-to-airbyte/resources/pull-requests-handbook/#pull-request-title-convention).
	6. Pat yourself on the back for being an awesome contributor.
	7. Someone from Airbyte will take a look at your PR and iterate with you to merge it into master.
long_description_content_type = text/markdown

[egg_info]
tag_build = 
tag_date = 0

