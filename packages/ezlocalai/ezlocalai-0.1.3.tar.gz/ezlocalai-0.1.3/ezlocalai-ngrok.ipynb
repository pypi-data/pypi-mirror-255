{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ezlocalai with ngrok\n",
    "\n",
    "Open this notebook in [Google Colab.](https://colab.research.google.com/)\n",
    "\n",
    "Set the resources to T4 GPU, free tier.\n",
    "\n",
    "[Get your free NGROK_TOKEN here.](https://dashboard.ngrok.com/get-started/your-authtoken) and add it to the colab secrets (Key logo on the left in Google Colab.)\n",
    "\n",
    "It takes several minutes to install dependencies and to start the server. You can see the ngrok URL in the cell output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update --fix-missing && apt-get upgrade -y\n",
    "!apt-get install -y --fix-missing --no-install-recommends git build-essential cmake gcc g++ portaudio19-dev ffmpeg libportaudio2 libasound-dev python3 python3-pip wget ocl-icd-opencl-dev opencl-headers clinfo libclblast-dev libopenblas-dev ninja-build python3.10-dev\n",
    "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
    "!ln -s /usr/bin/python3 /usr/bin/python\n",
    "!apt-get clean && rm -rf /var/lib/apt/lists/* /var/cache/apt/* /tmp/* /var/tmp/*\n",
    "!python3 -m pip install --upgrade pip cmake scikit-build setuptools wheel pyngrok --no-cache-dir\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python --no-cache-dir\n",
    "!rm -rf sample_data .config\n",
    "!git clone https://github.com/DevXT-LLC/ezlocalai .\n",
    "!pip install -r cuda-requirements.txt\n",
    "!sed -i 's/WHISPER_MODEL=base.en/WHISPER_MODEL=large-v3/g' .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your NGROK_TOKEN to your colab secrets if using Google Colab (Key logo on the left)\n",
    "try:\n",
    "  from google.colab import userdata\n",
    "  NGROK_TOKEN = userdata.get('NGROK_TOKEN')\n",
    "  if not NGROK_TOKEN:\n",
    "    raise\n",
    "except:\n",
    "  # If you're not using Google Colab, enter your NGROK_TOKEN below.\n",
    "  NGROK_TOKEN = \"YOUR NGROK_TOKEN HERE\"\n",
    "from pyngrok import ngrok\n",
    "ngrok.set_auth_token(NGROK_TOKEN)\n",
    "public_url = ngrok.connect(8091)\n",
    "print(f\"Public URL: {public_url}\")\n",
    "print(f\"Please wait for the server to say it is ready before trying to connect externally.\")\n",
    "!uvicorn app:app --host 0.0.0.0 --port 8091 --workers 1 --proxy-headers\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
