# SPDX-FileCopyrightText: Copyright 2016, Siavash Ameli <sameli@berkeley.edu>
# SPDX-License-Identifier: BSD-3-Clause
# SPDX-FileType: SOURCE
#
# This program is free software: you can redistribute it and/or modify it under
# the terms of the license found in the LICENSE.txt file in the root directory
# of this source tree.


# ======
# Import
# ======

import numpy
from .._plots._plot_utilities import plt, matplotlib, show_or_save_plot, \
        get_theme

__all__ = ['plot_convergence']


# =============
# Fit Power Law
# =============

def _fit_power_law(x, y):
    """
    Fits data to y = a x^b.
    By taking logarithm, this is a linear regression to find a and b.
    """

    log_x = numpy.log10(x)
    log_y = numpy.log10(y)
    poly_fit = numpy.polyfit(log_x, log_y, 1)
    log_y_fit = numpy.polyval(poly_fit, log_x)
    y_fit = 10**(log_y_fit)
    slope = poly_fit[0]

    return y_fit, slope


# ================
# Plot Convergence
# ================

@matplotlib.rc_context(get_theme(font_scale=1.2))
def plot_convergence(
        missing_indices_in_ocean_inside_hull,
        U_all_ensembles_inpainted,
        V_all_ensembles_inpainted,
        U_all_ensembles_inpainted_stats,
        V_all_ensembles_inpainted_stats,
        save=True,
        verbose=True):
    """
    """

    # _plot_convergence_1(
    #         missing_indices_in_ocean_inside_hull, U_all_ensembles_inpainted,
    #         V_all_ensembles_inpainted, save=save, verbose=verbose)

    _plot_convergence_wrt_mean(
            missing_indices_in_ocean_inside_hull, U_all_ensembles_inpainted,
            V_all_ensembles_inpainted, U_all_ensembles_inpainted_stats,
            V_all_ensembles_inpainted_stats, save=save, verbose=verbose)

    _plot_convergence_wrt_central(
            missing_indices_in_ocean_inside_hull, U_all_ensembles_inpainted,
            V_all_ensembles_inpainted, U_all_ensembles_inpainted_stats,
            V_all_ensembles_inpainted_stats, save=save, verbose=verbose)


# ================
# Plot convergence
# ================

def _plot_convergence_1(
        missing_indices_in_ocean_inside_hull,
        U_all_ensembles_inpainted,
        V_all_ensembles_inpainted,
        save=True,
        verbose=True):
    """
    """

    # Note: The first ensemble is not generated by random process, since it
    # is the central ensemble. So we exclude it.
    num_samples = U_all_ensembles_inpainted.shape[0] - 1
    means_U = numpy.zeros(
            (num_samples, missing_indices_in_ocean_inside_hull.shape[0]),
            dtype=float)
    means_V = numpy.zeros(
            (num_samples, missing_indices_in_ocean_inside_hull.shape[0]),
            dtype=float)

    # Mean of ensembles from the second ensemble to the i-th where i
    # varies to the end of array. We do not take to account of the first
    # ensemble since it is the central ensemble and was not generated by
    # Gaussian random process. Also means are obtained from only the points
    # that were inpainted, not from the valid points.
    for ensemble in range(num_samples):
        for point_id in range(
                missing_indices_in_ocean_inside_hull.shape[0]):
            index_I, index_J = \
                    missing_indices_in_ocean_inside_hull[point_id, :]
            means_U[ensemble, point_id] = \
                numpy.ma.mean(U_all_ensembles_inpainted[
                    1:ensemble+2, index_I, index_J])
            means_V[ensemble, point_id] = \
                numpy.ma.mean(V_all_ensembles_inpainted[
                    1:ensemble+2, index_I, index_J])

    # Difference of each consecutive mean
    diff_means_U = numpy.max(numpy.abs(numpy.diff(means_U, axis=0)),
                             axis=1)
    diff_means_V = numpy.max(numpy.abs(numpy.diff(means_V, axis=0)),
                             axis=1)

    # Fitting log of curves with a line
    x = numpy.arange(1, num_samples)
    diff_means_U_fit, slope_U = _fit_power_law(x, diff_means_U)
    diff_means_V_fit, slope_V = _fit_power_law(x, diff_means_V)

    # Plot
    fig, ax = plt.subplots()
    ax.plot(diff_means_U, color='lightsteelblue', zorder=0,
            label='East velocity data')
    ax.plot(diff_means_U_fit, color='darkblue', zorder=1,
            label='East Velocity Data (fit, slope: %0.2f)' % slope_U)
    ax.plot(diff_means_V, color='palegreen', zorder=0,
            label='North velocity data')
    ax.plot(diff_means_V_fit, color='green', zorder=1,
            label='North Velocity Data (fit, slope: %0.2f)' % slope_V)

    ax.set_xscale('log')
    ax.set_yscale('log')
    ax.set_xlim([x[1], x[-1]])
    ax.grid(True)
    ax.legend(loc='lower left', fontsize='x-small')
    ax.set_xlabel(r'Number of Samples $s$')
    ax.set_ylabel('Max Mean Difference')
    ax.set_title('Convergence of Mean of Ensemble')

    fig.set_tight_layout(True)

    # Save plot
    if save:
        filename = 'ensemble_convergence_1'
        show_or_save_plot(plt, filename=filename, transparent_background=True,
                          bbox_extra_artists=None, verbose=verbose)


# =========================
# Plot convergence wrt mean
# =========================

def _plot_convergence_wrt_mean(
        missing_indices_in_ocean_inside_hull,
        U_all_ensembles_inpainted,
        V_all_ensembles_inpainted,
        U_all_ensembles_inpainted_stats,
        V_all_ensembles_inpainted_stats,
        save=True,
        verbose=True):
    """
    Plots convergence of ensemble w.r.t the mean of all ensemble (not the
    central ensemble).

    The other function _plot_convergence_wrt_central plots the convergence
    w.r.t to the central ensemble (not the mean.)

    In the valid domain, the mean and observed realization are the same.
    However, in the unknown domain, they are different.

    This function plots convergence of the difference of the ensemble and the
    mean of ensemble ONLY on the unknown domain where the missing data were
    inpainted. Hence, the mean and central ensemble are not the same.

    The cumulative mean of the ensemble convergences to the mean of the total
    number of the ensemble, however, they are not necessarily converge to the
    central ensemble.
    """

    indices = missing_indices_in_ocean_inside_hull

    # Note: The first ensemble is not generated by random process, since it
    # is the central ensemble. So we exclude it by subtracting one.
    num_samples = U_all_ensembles_inpainted.shape[0] - 1

    means_U = numpy.ma.masked_all((num_samples, indices.shape[0]),
                                  dtype=float)
    means_V = numpy.ma.masked_all((num_samples, indices.shape[0]),
                                  dtype=float)

    U_data = U_all_ensembles_inpainted[1:, :, :]
    V_data = V_all_ensembles_inpainted[1:, :, :]

    # Mean of ensembles from the second ensemble to the i-th where i varies
    # to the end of array. We do not take to account of the first ensemble
    # since it is the central ensemble and was not generated by Gaussian
    # random process. Also means are obtained from only the points that
    # were inpainted, not from the valid points.
    for ensemble in range(num_samples):
        if verbose:
            print('ensemble: %d' % ensemble)
        for point_id in range(indices.shape[0]):
            index_I, index_J = indices[point_id, :]
            means_U[ensemble, point_id] = \
                numpy.ma.mean(U_data[:ensemble+1, index_I, index_J])
            means_V[ensemble, point_id] = \
                numpy.ma.mean(V_data[:ensemble+1, index_I, index_J])

    # mean_diff_mean_U = numpy.mean(numpy.abs(means_U - means_U[-1, :]),
    #                               axis=1)
    # mean_diff_mean_V = numpy.mean(numpy.abs(means_V - means_V[-1, :]),
    #                               axis=1)

    U_errors = numpy.empty((indices.shape[0]), dtype=float)
    V_errors = numpy.empty((indices.shape[0]), dtype=float)
    for point_id in range(indices.shape[0]):
        index_I, index_J = indices[point_id, :]
        U_errors[point_id] = U_all_ensembles_inpainted_stats['STD'][
                0, index_I, index_J]
        V_errors[point_id] = V_all_ensembles_inpainted_stats['STD'][
                0, index_I, index_J]

    # Mean of diff of means of s ensembles from the total S samples (s=1,...,S)
    mean_diff_mean_U = numpy.mean(numpy.abs(means_U - means_U[-1, :]) /
                                  U_errors, axis=1)
    mean_diff_mean_V = numpy.mean(numpy.abs(means_V - means_V[-1, :]) /
                                  V_errors, axis=1)

    # STD of diff of means of s ensembles from the total S samples (s=1,...,S)
    std_diff_mean_U = numpy.std(numpy.abs(means_U - means_U[-1, :]) /
                                U_errors, axis=1)
    std_diff_mean_V = numpy.std(numpy.abs(means_V - means_V[-1, :]) /
                                V_errors, axis=1)

    # Z score for 84% confidence interval
    z_score = 1.0

    # Plot
    fig, ax = plt.subplots(figsize=(5.7, 4.2))

    yu = mean_diff_mean_U
    yv = mean_diff_mean_V

    yu_up = mean_diff_mean_U + z_score * std_diff_mean_U
    yu_dn = mean_diff_mean_U - z_score * std_diff_mean_U
    yu_dn[yu_dn <= 0.0] = 1e-4

    yv_up = mean_diff_mean_V + z_score * std_diff_mean_V
    yv_dn = mean_diff_mean_V - z_score * std_diff_mean_V
    yv_dn[yv_dn <= 0.0] = 1e-4

    # N = yu.size
    N = yu.size // 2
    x = numpy.arange(1, N+1)

    ax.plot(x, yu[:N], color='orangered',
            label=(r'East Velocity Data'))
    yu_fit, slope_u = _fit_power_law(x, yu[:N])
    ax.plot(x, yu_fit, '--', color='orangered',
            label='East Velocity Data (fit, slope: %0.2f)' % slope_u)
    ax.fill_between(x, yu_dn[:N], yu_up[:N], color='orange',
                    label=(r'84\% Confidence Bound (std)'))

    ax.plot(x, yv[:N], color='green',
            label=r'North Velocity Data')
    yv_fit, slope_v = _fit_power_law(x, yv[:N])
    ax.plot(x, yv_fit, '--', color='green',
            label='North Velocity Data (fit, slope: %0.2f)' % slope_v)
    ax.fill_between(x, yv_dn[:N], yv_up[:N], color='palegreen',
                    label=r'84\% Confidence Bound (std)')

    ax.set_xscale('log')
    ax.set_yscale('log')
    ax.grid(True)
    ax.set_xlim([x[0], x[-1]])
    ax.set_ylim([1e-3, 1])
    ax.legend(loc='lower left', fontsize='x-small')
    ax.set_xlabel(r'Number of samples $s$')
    ax.set_ylabel(r'$\epsilon_s$')
    ax.set_title('Convergence of Mean of Ensemble')

    fig.set_tight_layout(True)

    # Save plot
    if save:
        filename = 'ensemble_convergence_wrt_mean'
        show_or_save_plot(plt, filename=filename, transparent_background=True,
                          bbox_extra_artists=None, verbose=verbose)


# ==================
# Plot convergence 3
# ==================

def _plot_convergence_wrt_central(
        missing_indices_in_ocean_inside_hull,
        U_all_ensembles_inpainted,
        V_all_ensembles_inpainted,
        U_all_ensembles_inpainted_stats,
        V_all_ensembles_inpainted_stats,
        save=True,
        verbose=True):
    """
    Plots convergence of ensemble w.r.t the central ensemble (not the mean).

    The other function _plot_convergence_wrt_mean plots the convergence w.r.t
    to the mean of all ensemble (not central ensemble.)

    In the valid domain, the mean and observed realization are the same.
    However, in the unknown domain, they are different.

    This function plots convergence of the difference of the ensemble and the
    central ensemble ONLY on the unknown domain where the missing data were
    inpainted. Hence, the mean and central ensemble are not the same.

    The cumulative mean of the ensemble convergences to the mean of the total
    number of the ensemble, however, they are not necessarily converge to the
    central ensemble.
    """

    indices = missing_indices_in_ocean_inside_hull

    # Note: The first ensemble is not generated by random process, since it
    # is the central ensemble. So we exclude it.
    num_samples = U_all_ensembles_inpainted.shape[0] - 1

    # Allocate data, mean and their std
    U = numpy.zeros((num_samples, indices.shape[0]), dtype=float)
    V = numpy.zeros((num_samples, indices.shape[0]), dtype=float)
    U_central = numpy.zeros((indices.shape[0], ), dtype=float)
    V_central = numpy.zeros((indices.shape[0], ), dtype=float)
    U_std = numpy.zeros((indices.shape[0], ), dtype=float)
    V_std = numpy.zeros((indices.shape[0], ), dtype=float)

    # Data are obtained from only the points that were inpainted, not from the
    # valid points since on the valid points, all ensembles are the same.
    for point_id in range(indices.shape[0]):
        index_I, index_J = indices[point_id, :]
        U[:, point_id] = U_all_ensembles_inpainted[1:, index_I, index_J]
        V[:, point_id] = V_all_ensembles_inpainted[1:, index_I, index_J]

    # Mean and std of ensembles
    for point_id in range(indices.shape[0]):
        index_I, index_J = indices[point_id, :]

        # Central ensemble is the zeroth index
        U_central[point_id] = U_all_ensembles_inpainted[0, index_I, index_J]
        V_central[point_id] = V_all_ensembles_inpainted[0, index_I, index_J]

        # STD of ensembles
        U_std[point_id] = U_all_ensembles_inpainted_stats['STD'][
                0, index_I, index_J]
        V_std[point_id] = V_all_ensembles_inpainted_stats['STD'][
                0, index_I, index_J]

    # Z score of data
    U_z_score = numpy.zeros((num_samples, indices.shape[0]), dtype=float)
    V_z_score = numpy.zeros((num_samples, indices.shape[0]), dtype=float)
    for ensemble in range(num_samples):
        U_z_score[ensemble, :] = (U[ensemble, :] - U_central) / U_std
        V_z_score[ensemble, :] = (V[ensemble, :] - V_central) / V_std

    # Cumulative std of the z-scores
    U_cum_mean = numpy.zeros((num_samples, indices.shape[0]), dtype=float)
    V_cum_mean = numpy.zeros((num_samples, indices.shape[0]), dtype=float)
    for ensemble in range(num_samples):
        U_cum_mean[ensemble, :] = numpy.mean(U_z_score[:ensemble+1, :], axis=0)
        V_cum_mean[ensemble, :] = numpy.mean(V_z_score[:ensemble+1, :], axis=0)

    # U_cum_mean_std = numpy.zeros((num_samples-1, indices.shape[0]),
    #                              dtype=float)
    # V_cum_mean_std = numpy.zeros((num_samples-1, indices.shape[0]),
    #                              dtype=float)
    # for ensemble in range(1, num_samples):
    #     U_cum_mean_std[ensemble-1, :] = \
    #         numpy.std(U_cum_mean[:ensemble, :], axis=0)
    #     V_cum_mean_std[ensemble-1, :] = \
    #         numpy.std(V_cum_mean[:ensemble, :], axis=0)

    # Plot
    fig, ax = plt.subplots(figsize=(5.7, 4.2))

    yu = numpy.mean(U_cum_mean, axis=1)
    yv = numpy.mean(V_cum_mean, axis=1)

    N = yu.size
    # N = yu.size // 2
    x = numpy.arange(1, N+1)

    ax.plot(x, yu[:N], color='orangered',
            label=(r'East Velocity Data'))
    yu_fit, slope_u = _fit_power_law(x, yu[:N])
    ax.plot(x, yu_fit, '--', color='orangered',
            label='East Velocity Data (fit, slope: %0.2f)' % slope_u)
    # ax.fill_between(x, yu_dn[:N], yu_up[:N], color='orange',
    #                 label=(r'84\% Confidence Bound (std)'))

    ax.plot(x, yv[:N], color='green',
            label=r'North Velocity Data')
    yv_fit, slope_v = _fit_power_law(x, yv[:N])
    ax.plot(x, yv_fit, '--', color='green',
            label='North Velocity Data (fit, slope: %0.2f)' % slope_v)
    # ax.fill_between(x, yv_dn[:N], yv_up[:N], color='palegreen',
    #                 label=r'84\% Confidence Bound (std)')

    ax.set_xscale('log')
    ax.set_yscale('log')
    ax.grid(True)
    ax.set_xlim([x[0], x[-1]])
    # ax.set_ylim([1e-3, 1])
    ax.legend(loc='lower left', fontsize='x-small')
    ax.set_xlabel(r'Number of samples $s$')
    ax.set_ylabel(r'$\epsilon_s$')
    ax.set_title('Convergence of Mean of Ensemble')

    fig.set_tight_layout(True)

    # Save plot
    if save:
        filename = 'ensemble_convergence_wrt_central'
        show_or_save_plot(plt, filename=filename, transparent_background=True,
                          bbox_extra_artists=None, verbose=verbose)
