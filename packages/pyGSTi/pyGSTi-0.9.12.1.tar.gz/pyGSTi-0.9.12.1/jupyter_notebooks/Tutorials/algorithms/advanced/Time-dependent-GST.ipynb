{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-dependent models and gate set tomography\n",
    "This tutorial demonstrates how time dependence can be added to models in pyGSTi and, since gate set tomography (GST) just optimizes model parameters, how to run time-dependent GST.  \n",
    "\n",
    "<font style=\"color:red\">**Notice: this topic describes \"beta level\" functionality in pyGSTi!**  It may contain bugs and holes in its implementation, which will be addressed in future releases.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygsti\n",
    "from pygsti.modelpacks import smq1Q_XYI\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time dependent models\n",
    "To make a time-dependent `Model`, you create a time dependent gate or operation and add this to any of the models in pyGSTi.  (**Expert note**: this isn't quite true - currently, only models with `sim_type=\"map\"` support time-dependent evaluation of circuit outcomes, so we're currently limited to using this simulation type.)  Here's an example of how to make a custom idle operation that depolarizes its input state more and more over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTimeDependentIdle(pygsti.modelmembers.operations.DenseOperator):\n",
    "    \"\"\"And idle that depolarizes over time with a parameterized rate\"\"\"\n",
    "    def __init__(self, initial_depol_rate):\n",
    "        #initialize with no noise\n",
    "        super(MyTimeDependentIdle,self).__init__(np.identity(4,'d'), 'pp', \"densitymx\") # this is *super*-operator, so \"densitymx\"\n",
    "        self.from_vector([initial_depol_rate]) \n",
    "        self.set_time(0.0)\n",
    "    \n",
    "    @property\n",
    "    def num_params(self): \n",
    "        return 1 # we have two parameters\n",
    "    \n",
    "    def to_vector(self):\n",
    "        return np.array([self.depol_rate],'d') #our parameter vector\n",
    "        \n",
    "    def from_vector(self, v, close=False, dirty_value=True):\n",
    "        #initialize from parameter vector v\n",
    "        self.depol_rate = v[0]\n",
    "        self.dirty = dirty_value # mark that paramvec (self.to_vector()) may have changed\n",
    "        \n",
    "    def set_time(self,t):\n",
    "        a = 1.0-min(self.depol_rate*t,1.0)\n",
    "        \n",
    "        # ._ptr is a member of DenseOperator and is a reference to a\n",
    "        # numpy array that is the dense Pauli transfer matrix of this operator\n",
    "        # Technical note: use [:,:] here b/c we don't want to change id of self.base\n",
    "        self._ptr[:,:] = np.array([[1,   0,   0,   0],\n",
    "                                   [0,   a,   0,   0],\n",
    "                                   [0,   0,   a,   0],\n",
    "                                   [0,   0,   0,   a]],'d')\n",
    "        \n",
    "    def transform(self, S):\n",
    "        # Update self with inverse(S) * self * S (used in gauge optimization)\n",
    "        raise NotImplementedError(\"MyTimeDependentIdle cannot be transformed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key piece to note in the above class is the `set_time` method, which will be called sometime after `from_vector` and takes over responsiblility (from `from_vector`) for setting the object's `.base` member to the process matrix based on the parameters (in `from_vector`'s `v` *and* the time given to `set_time`). \n",
    "\n",
    "Here's an example of how to see what a `MyTimeDependentIdle(1.0)` gate looks like at the time 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.  0.  0. ]\n",
      " [0.  0.9 0.  0. ]\n",
      " [0.  0.  0.9 0. ]\n",
      " [0.  0.  0.  0.9]]\n"
     ]
    }
   ],
   "source": [
    "t = 0.1\n",
    "Gi_at_t = MyTimeDependentIdle(1.0)\n",
    "Gi_at_t.set_time(t)\n",
    "Gi_matrix_at_t = Gi_at_t.to_dense()\n",
    "print(Gi_matrix_at_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a `MyTimeDependentIdle` gate to a model just like any other operator (in pyGSTi all operators are considered potentially time-dependent, and so the base class of our idle gate is `DenseOperator` just as it would be if we were creating a custom time-independent gate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = smq1Q_XYI.target_model(simulator=\"map\")\n",
    "mdl['Gi'] = MyTimeDependentIdle(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have it - `mdl` is a time-dependent model, where `Gi` depolarizes with strength equal to the current time.  To compute the probability of a circuit, *GiGi* for example, we just call the usual `probs` function but specify a `time` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutcomeLabelDict([(('0',), 0.9050000000000002), (('1',), 0.09499999999999997)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.probabilities( ('Gi','Gi'), time=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zero probability is equal to `0.5 * (1 + 0.9**2) = 0.905`, where the `0.9` comes from the Gi gate depolarization rate of 0.1 at time 0.1.  Note that this is the same as what you'd get using the `Gi_matrix_at_t` above (since our \"t\" was 0.1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.905]]\n"
     ]
    }
   ],
   "source": [
    "E = mdl['Mdefault']['0']\n",
    "rho = mdl['rho0']\n",
    "print(np.dot(E.T, np.dot(Gi_matrix_at_t, np.dot(Gi_matrix_at_t, rho))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-dependent (or \"time aware\") circuits\n",
    "`Circuit` objects may include time information: labels within a circuit (e.g. `\"Gi\"`) may contain a *relative* time giving the duration of the operation being labeled.  By default, all labels have zero duration, meaning all the operations within the circuit are interpreted as occurring at the same time.  The below example gives the `Gi` gate a duration of 0.1, so that in the circuit simulation the first `Gi` occurs at time 0.1 and the second at 0.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutcomeLabelDict([(('0',), 0.8600000000000002), (('1',), 0.14)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gi_with_duration = pygsti.baseobjs.Label('Gi',time=0.1)\n",
    "mdl.probabilities( (Gi_with_duration, Gi_with_duration), time=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.86]]\n"
     ]
    }
   ],
   "source": [
    "Gi_at_t.set_time(0.1)\n",
    "Gi_matrix_at_t1 = Gi_at_t.to_dense().copy()  # .copy() is needed because copies of the internal dense rep are not made by default (for performance)\n",
    "Gi_at_t.set_time(0.2)\n",
    "Gi_matrix_at_t2 = Gi_at_t.to_dense().copy()\n",
    "print(np.dot(E.T, np.dot(Gi_matrix_at_t2, np.dot(Gi_matrix_at_t1, rho))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the following \"!\"-shorthand (exclamation point followed by time) notation to specify label durations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OutcomeLabelDict([(('0',), 0.8600000000000002), (('1',), 0.14)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.probabilities( (('Gi','!0.1'),('Gi','!0.1')), time=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time dependent data\n",
    "When `DataSet` objects contain timestamped data, these timestamps indicate at what *absolute* time the relevant circuit began executing when it produced certain data.  These time values correspond to those given to the `time` argument of `probs` above.\n",
    "\n",
    "At first, we don't bother with \"time-aware\" circuits, and just create a list of two sample circuits.  We then use the `times` argument of `generate_fake_data` to construct a `DataSet` with 100 samples of data taken at each of three times: 0, 0.1, and 0.2 (arbitrary time units).  By setting `sample_error=\"none\"` we can see the underlying outcome probabilities in the data (and how the depolarization caused by `Gi` increases with time): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset outcomes: OrderedDict([(('0',), 0), (('1',), 1)])\n",
      "Gi :\n",
      "Outcome Label Indices = [0 1 0 1 0 1]\n",
      "Time stamps = [0.  0.  0.1 0.1 0.2 0.2]\n",
      "Repetitions = [100.   0.  95.   5.  90.  10.]\n",
      "\n",
      "GiGi :\n",
      "Outcome Label Indices = [0 1 0 1 0 1]\n",
      "Time stamps = [0.  0.  0.1 0.1 0.2 0.2]\n",
      "Repetitions = [100.    0.   90.5   9.5  82.   18. ]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "circuits = pygsti.circuits.to_circuits([ ('Gi',), ('Gi','Gi')]) # just pick some circuits\n",
    "\n",
    "ds = pygsti.data.simulate_data(mdl, circuits, num_samples=100,\n",
    "                                       sample_error='none', seed=1234, times=[0,0.1,0.2])\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataSet` with timestamps displays 3 parallel arrays for each circuit: \"Outcome Label Indices\", \"Time stamps\", and \"Repetitions\".  Each index corresponds to a bin of some number (given by \"Repetitions\") of X-outcomes (X given by \"Outcome Label Indices\") occuring at some time (given by \"Time stamps\").  We see that for each of the two circuits there are bins of 0- and 1-outcomes at each of times 0, 0.1, and 0.2.  Summing the bin counts (outcome repetitions) at each time, for a given circuit, gives 100.\n",
    "\n",
    "We can also add a duration of 0.05 time units to each `\"Gi\"` gate.  This makes the depolarization of the length-2 sequence a bit worse because the second application of `\"Gi\"` occurs at a time 0.05 units after the start of the circuit, at which point the noise on the gate as increased:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset outcomes: OrderedDict([(('0',), 0), (('1',), 1)])\n",
      "Gi!0.05 :\n",
      "Outcome Label Indices = [0 1 0 1 0 1]\n",
      "Time stamps = [0.  0.  0.1 0.1 0.2 0.2]\n",
      "Repetitions = [100.   0.  95.   5.  90.  10.]\n",
      "\n",
      "Gi!0.05Gi!0.05 :\n",
      "Outcome Label Indices = [0 1 0 1 0 1]\n",
      "Time stamps = [0.  0.  0.1 0.1 0.2 0.2]\n",
      "Repetitions = [97.5   2.5  88.25 11.75 80.   20.  ]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "circuits = pygsti.circuits.to_circuits([ (('Gi','!0.05'),), (('Gi','!0.05'),('Gi','!0.05'))])\n",
    "\n",
    "ds = pygsti.data.simulate_data(mdl, circuits, num_samples=100,\n",
    "                                       sample_error='none', seed=1234, times=[0,0.1,0.2])\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-dependent gate set tomography (TD-GST)\n",
    "To run gate set tomography, we'll need more sequences than the two in the example above.  We'll generate some timestamped data for the standard set of GST sequences for a 1-qubit $X(\\pi/2)$, $Y(\\pi/2)$, $I$ gate set.  In particular, we create a data-generating model that has a `MyTimeDependentIdle` idle gate (labeled by the empty-tuple) with a depolarization \"acceleration\" rate of 1.0, and we generate 10 counts at each of 10 equally spaced times between 0 and 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_fiducials, meas_fiducials = smq1Q_XYI.prep_fiducials(), smq1Q_XYI.meas_fiducials()\n",
    "germs = smq1Q_XYI.germs()\n",
    "maxLengths = [1, 2]\n",
    "idle_gate_label = () # the smq1Q_XYI model labels an idle circuit layer by an empty tuple, not 'Gi'\n",
    "\n",
    "mdl_datagen = smq1Q_XYI.target_model(simulator=\"map\").depolarize(op_noise=0.01, spam_noise=0.001)\n",
    "mdl_datagen[idle_gate_label] = MyTimeDependentIdle(1.0)\n",
    "mdl_datagen.num_params\n",
    "\n",
    "edesign = pygsti.protocols.StandardGSTDesign(smq1Q_XYI.target_model(), prep_fiducials,\n",
    "                                             meas_fiducials, germs, maxLengths)\n",
    "\n",
    "#Data for initial non-sparse mode\n",
    "ds = pygsti.data.simulate_data(mdl_datagen, edesign.all_circuits_needing_data, num_samples=10,\n",
    "                                       sample_error=\"binomial\", seed=1234, times=np.linspace(0,0.3,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run GST on this timestamped data similar to any other data, using the `GateSetTomography` protocol.  The key difference is that a `TimeDependentPoissonPicLogLFunction` objective function is used, which evaluates the log-likelihood by accounting separately for each timestamp.  It takes the timestamps in the given `DataSet` seriously, and performs time-dependent circuit simulations rather than aggregating the counts across all times (the behavior when the default objective function is used).\n",
    "\n",
    "Running time-dependent GST with 10 timesteps requires 10 times the number of circuit simulations (each circuit needs to be simulated 10 times).  This, coupled with the fact that this the time-dependent simulation routines are less optimized in pyGSTi, means this running time-dependent GST is significantly slower than normal GST.  Note also that we set `gauge_opt_suite=None`.  This disables gauge optimization, and this is necessary since it won't work because our `MyTimeDependentIdle` operation doesn't implement `transform` (the action of a gauge transformation).\n",
    "\n",
    "The cell below will take around 5 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iterative GST: Iter 1 of 2  92 circuits ---: \n",
      "  MapLayout: 1 processors divided into 1 x 1 (= 1) grid along circuit and parameter directions.\n",
      "     8 atoms, parameter block size limits (None,)\n",
      "  *** Distributing 8 atoms to 1 atom-processing groups (1 cores) ***\n",
      "      More atom-processors than hosts: each host gets ~1 atom-processors\n",
      "      Atom-processors already occupy a single node, dividing atom-processor into 1 param-processors.\n",
      "  *** Divided 1-host atom-processor (~1 procs) into 1 param-processing groups ***\n",
      "  --- TimeDependentPoissonPicLogLFunction GST ---\n",
      "    --- Outer Iter 0: norm_f = 1458.18, mu=1, |x|=2.73861, |J|=84056.2\n",
      "        - Inner Loop: mu=1124.47, norm_dx=1.45626e-06\n",
      "            (cont): norm_new_f=955.104, dL=1111.98, dF=503.078, reldL=0.762583, reldF=0.345003\n",
      "            Accepted! gain ratio=0.452414  mu * 1.00086 => 1125.44\n",
      "    --- Outer Iter 1: norm_f = 955.104, mu=1125.44, |x|=2.73835, |J|=7225.05\n",
      "        - Inner Loop: mu=1125.44, norm_dx=2.64525e-05\n",
      "            (cont): norm_new_f=661.735, dL=561.942, dF=293.369, reldL=0.588357, reldF=0.307159\n",
      "            Accepted! gain ratio=0.522062  mu * 0.999914 => 1125.34\n",
      "    --- Outer Iter 2: norm_f = 661.735, mu=1125.34, |x|=2.73558, |J|=1000.98\n",
      "        - Inner Loop: mu=1125.34, norm_dx=5.29004e-05\n",
      "            (cont): norm_new_f=566.661, dL=86.3544, dF=95.0744, reldL=0.130497, reldF=0.143674\n",
      "            Accepted! gain ratio=1.10098  mu * 0.333333 => 375.113\n",
      "    --- Outer Iter 3: norm_f = 566.661, mu=375.113, |x|=2.73022, |J|=444.999\n",
      "        - Inner Loop: mu=375.113, norm_dx=6.84181e-05\n",
      "            (cont): norm_new_f=529.67, dL=28.4205, dF=36.9905, reldL=0.0501543, reldF=0.065278\n",
      "            Accepted! gain ratio=1.30154  mu * 0.333333 => 125.038\n",
      "    --- Outer Iter 4: norm_f = 529.67, mu=125.038, |x|=2.72428, |J|=293.629\n",
      "        - Inner Loop: mu=125.038, norm_dx=0.000193623\n",
      "            (cont): norm_new_f=512.191, dL=13.9916, dF=17.4796, reldL=0.0264158, reldF=0.033001\n",
      "            Accepted! gain ratio=1.24929  mu * 0.333333 => 41.6792\n",
      "    --- Outer Iter 5: norm_f = 512.191, mu=41.6792, |x|=2.72059, |J|=222.497\n",
      "        - Inner Loop: mu=41.6792, norm_dx=0.00119679\n",
      "            (cont): norm_new_f=502.974, dL=6.6629, dF=9.2165, reldL=0.0130086, reldF=0.0179943\n",
      "            Accepted! gain ratio=1.38326  mu * 0.333333 => 13.8931\n",
      "    --- Outer Iter 6: norm_f = 502.974, mu=13.8931, |x|=2.72329, |J|=192.593\n",
      "        - Inner Loop: mu=13.8931, norm_dx=0.0105899\n",
      "            (cont): norm_new_f=487.572, dL=9.83005, dF=15.4024, reldL=0.0195439, reldF=0.0306226\n",
      "            Accepted! gain ratio=1.56686  mu * 0.333333 => 4.63102\n",
      "    --- Outer Iter 7: norm_f = 487.572, mu=4.63102, |x|=2.74577, |J|=186.93\n",
      "        - Inner Loop: mu=4.63102, norm_dx=0.0686085\n",
      "            (cont): norm_new_f=59020.7, dL=16.8328, dF=-58533.1, reldL=0.0345237, reldF=-120.05\n",
      "            Rejected!  mu => mu*nu = 9.26205, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=9.26205, norm_dx=0.0200332\n",
      "            (cont): norm_new_f=482.056, dL=9.25978, dF=5.51554, reldL=0.0189916, reldF=0.0113123\n",
      "            Accepted! gain ratio=0.595644  mu * 0.993 => 9.19722\n",
      "    --- Outer Iter 8: norm_f = 482.056, mu=9.19722, |x|=2.77247, |J|=2495.51\n",
      "        - Inner Loop: mu=9.19722, norm_dx=0.031166\n",
      "            (cont): norm_new_f=1014.24, dL=19.8836, dF=-532.186, reldL=0.0412474, reldF=-1.10399\n",
      "            Rejected!  mu => mu*nu = 18.3944, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=18.3944, norm_dx=0.00854571\n",
      "            (cont): norm_new_f=471.562, dL=15.5032, dF=10.4943, reldL=0.0321606, reldF=0.0217698\n",
      "            Accepted! gain ratio=0.676908  mu * 0.955708 => 17.5797\n",
      "    --- Outer Iter 9: norm_f = 471.562, mu=17.5797, |x|=2.78264, |J|=337.615\n",
      "        - Inner Loop: mu=17.5797, norm_dx=0.00998894\n",
      "            (cont): norm_new_f=466.6, dL=8.15748, dF=4.96203, reldL=0.0172989, reldF=0.0105225\n",
      "            Accepted! gain ratio=0.608279  mu * 0.989844 => 17.4012\n",
      "    --- Outer Iter 10: norm_f = 466.6, mu=17.4012, |x|=2.79289, |J|=153.455\n",
      "        - Inner Loop: mu=17.4012, norm_dx=0.0198957\n",
      "            (cont): norm_new_f=30022, dL=10.548, dF=-29555.4, reldL=0.0226062, reldF=-63.3421\n",
      "            Rejected!  mu => mu*nu = 34.8023, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=34.8023, norm_dx=0.00513341\n",
      "            (cont): norm_new_f=468.493, dL=6.14822, dF=-1.89275, reldL=0.0131766, reldF=-0.00405647\n",
      "            Rejected!  mu => mu*nu = 139.209, nu => 2*nu = 8\n",
      "        - Inner Loop: mu=139.209, norm_dx=0.000326693\n",
      "            (cont): norm_new_f=463.733, dL=1.78423, dF=2.86706, reldL=0.00382389, reldF=0.00614458\n",
      "            Accepted! gain ratio=1.60689  mu * 0.333333 => 46.4031\n",
      "    --- Outer Iter 11: norm_f = 463.733, mu=46.4031, |x|=2.79745, |J|=171.024\n",
      "        - Inner Loop: mu=46.4031, norm_dx=0.002531\n",
      "            (cont): norm_new_f=460.641, dL=2.14449, dF=3.09156, reldL=0.00462441, reldF=0.00666668\n",
      "            Accepted! gain ratio=1.44163  mu * 0.333333 => 15.4677\n",
      "    --- Outer Iter 12: norm_f = 460.641, mu=15.4677, |x|=2.80591, |J|=225.884\n",
      "        - Inner Loop: mu=15.4677, norm_dx=0.0191469\n",
      "            (cont): norm_new_f=456.758, dL=4.19681, dF=3.88328, reldL=0.00911079, reldF=0.00843017\n",
      "            Accepted! gain ratio=0.925295  mu * 0.384596 => 5.94882\n",
      "    --- Outer Iter 13: norm_f = 456.758, mu=5.94882, |x|=2.82807, |J|=163.779\n",
      "        - Inner Loop: mu=5.94882, norm_dx=0.148192\n",
      "            (cont): norm_new_f=168561, dL=16.0542, dF=-168104, reldL=0.0351481, reldF=-368.038\n",
      "            Rejected!  mu => mu*nu = 11.8976, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=11.8976, norm_dx=0.0421518\n",
      "            (cont): norm_new_f=34961.4, dL=10.6471, dF=-34504.7, reldL=0.02331, reldF=-75.5426\n",
      "            Rejected!  mu => mu*nu = 47.5905, nu => 2*nu = 8\n",
      "        - Inner Loop: mu=47.5905, norm_dx=0.00288744\n",
      "            (cont): norm_new_f=454.566, dL=3.83053, dF=2.19244, reldL=0.00838633, reldF=0.0048\n",
      "            Accepted! gain ratio=0.57236  mu * 0.996969 => 47.4463\n",
      "    --- Outer Iter 14: norm_f = 454.566, mu=47.4463, |x|=2.84365, |J|=339.313\n",
      "        - Inner Loop: mu=47.4463, norm_dx=0.0025276\n",
      "            (cont): norm_new_f=453.491, dL=5.17926, dF=1.07441, reldL=0.0113939, reldF=0.0023636\n",
      "            Accepted! gain ratio=0.207445  mu * 1.20031 => 56.9505\n",
      "    --- Outer Iter 15: norm_f = 453.491, mu=56.9505, |x|=2.85093, |J|=166.683\n",
      "        - Inner Loop: mu=56.9505, norm_dx=0.00139499\n",
      "            (cont): norm_new_f=451.007, dL=3.11484, dF=2.48409, reldL=0.00686857, reldF=0.0054777\n",
      "            Accepted! gain ratio=0.797502  mu * 0.78935 => 44.9539\n",
      "    --- Outer Iter 16: norm_f = 451.007, mu=44.9539, |x|=2.86291, |J|=283.801\n",
      "        - Inner Loop: mu=44.9539, norm_dx=0.00253741\n",
      "            (cont): norm_new_f=450.42, dL=2.52299, dF=0.586996, reldL=0.00559413, reldF=0.00130152\n",
      "            Accepted! gain ratio=0.232659  mu * 1.15286 => 51.8254\n",
      "    --- Outer Iter 17: norm_f = 450.42, mu=51.8254, |x|=2.87294, |J|=176.225\n",
      "        - Inner Loop: mu=51.8254, norm_dx=0.000732501\n",
      "            (cont): norm_new_f=448.586, dL=2.33779, dF=1.834, reldL=0.00519024, reldF=0.00407176\n",
      "            Accepted! gain ratio=0.784504  mu * 0.815772 => 42.2778\n",
      "    --- Outer Iter 18: norm_f = 448.586, mu=42.2778, |x|=2.88153, |J|=280.724\n",
      "        - Inner Loop: mu=42.2778, norm_dx=0.00193976\n",
      "            (cont): norm_new_f=448.262, dL=2.19893, dF=0.324334, reldL=0.00490191, reldF=0.000723014\n",
      "            Accepted! gain ratio=0.147497  mu * 1.35041 => 57.0924\n",
      "    --- Outer Iter 19: norm_f = 448.262, mu=57.0924, |x|=2.89063, |J|=181.224\n",
      "        - Inner Loop: mu=57.0924, norm_dx=0.000131988\n",
      "            (cont): norm_new_f=446.529, dL=2.02353, dF=1.73283, reldL=0.00451417, reldF=0.00386565\n",
      "            Accepted! gain ratio=0.856337  mu * 0.63803 => 36.4267\n",
      "    --- Outer Iter 20: norm_f = 446.529, mu=36.4267, |x|=2.89406, |J|=268.07\n",
      "        - Inner Loop: mu=36.4267, norm_dx=0.00150081\n",
      "            (cont): norm_new_f=446.253, dL=1.60088, dF=0.275977, reldL=0.00358515, reldF=0.000618049\n",
      "            Accepted! gain ratio=0.172391  mu * 1.28129 => 46.6732\n",
      "    --- Outer Iter 21: norm_f = 446.253, mu=46.6732, |x|=2.90213, |J|=188.515\n",
      "        - Inner Loop: mu=46.6732, norm_dx=8.69969e-05\n",
      "            (cont): norm_new_f=444.948, dL=2.00524, dF=1.3049, reldL=0.00449352, reldF=0.00292412\n",
      "            Accepted! gain ratio=0.650743  mu * 0.972597 => 45.3942\n",
      "    --- Outer Iter 22: norm_f = 444.948, mu=45.3942, |x|=2.90282, |J|=289.967\n",
      "        - Inner Loop: mu=45.3942, norm_dx=0.000791168\n",
      "            (cont): norm_new_f=444.607, dL=1.98129, dF=0.340962, reldL=0.00445285, reldF=0.000766296\n",
      "            Accepted! gain ratio=0.172091  mu * 1.28207 => 58.1983\n",
      "    --- Outer Iter 23: norm_f = 444.607, mu=58.1983, |x|=2.90774, |J|=194.431\n",
      "        - Inner Loop: mu=58.1983, norm_dx=6.16469e-05\n",
      "            (cont): norm_new_f=443.268, dL=1.52392, dF=1.33878, reldL=0.00342757, reldF=0.00301115\n",
      "            Accepted! gain ratio=0.878509  mu * 0.566172 => 32.9503\n",
      "    --- Outer Iter 24: norm_f = 443.268, mu=32.9503, |x|=2.90751, |J|=266.845\n",
      "        - Inner Loop: mu=32.9503, norm_dx=0.000863667\n",
      "            (cont): norm_new_f=442.886, dL=1.16281, dF=0.382834, reldL=0.00262326, reldF=0.000863661\n",
      "            Accepted! gain ratio=0.329232  mu * 1.03984 => 34.263\n",
      "    --- Outer Iter 25: norm_f = 442.886, mu=34.263, |x|=2.91267, |J|=204.106\n",
      "        - Inner Loop: mu=34.263, norm_dx=0.000149476\n",
      "            (cont): norm_new_f=442.357, dL=1.75881, dF=0.528371, reldL=0.00397124, reldF=0.00119302\n",
      "            Accepted! gain ratio=0.300415  mu * 1.0636 => 36.4422\n",
      "    --- Outer Iter 26: norm_f = 442.357, mu=36.4422, |x|=2.91114, |J|=323.905\n",
      "        - Inner Loop: mu=36.4422, norm_dx=0.00119255\n",
      "            (cont): norm_new_f=442.133, dL=2.95282, dF=0.224572, reldL=0.00667519, reldF=0.00050767\n",
      "            Accepted! gain ratio=0.0760533  mu * 1.60957 => 58.6563\n",
      "    --- Outer Iter 27: norm_f = 442.133, mu=58.6563, |x|=2.91727, |J|=201.683\n",
      "        - Inner Loop: mu=58.6563, norm_dx=0.000175305\n",
      "            (cont): norm_new_f=441.013, dL=1.8638, dF=1.1196, reldL=0.00421547, reldF=0.00253228\n",
      "            Accepted! gain ratio=0.600711  mu * 0.991828 => 58.1769\n",
      "    --- Outer Iter 28: norm_f = 441.013, mu=58.1769, |x|=2.91593, |J|=293.874\n",
      "        - Inner Loop: mu=58.1769, norm_dx=0.000228422\n",
      "            (cont): norm_new_f=440.567, dL=0.995595, dF=0.446361, reldL=0.00225752, reldF=0.00101213\n",
      "            Accepted! gain ratio=0.448336  mu * 1.0011 => 58.2411\n",
      "    --- Outer Iter 29: norm_f = 440.567, mu=58.2411, |x|=2.91763, |J|=223.88\n",
      "        - Inner Loop: mu=58.2411, norm_dx=2.53496e-05\n",
      "            (cont): norm_new_f=440.077, dL=0.513235, dF=0.48971, reldL=0.00116494, reldF=0.00111155\n",
      "            Accepted! gain ratio=0.954165  mu * 0.333333 => 19.4137\n",
      "    --- Outer Iter 30: norm_f = 440.077, mu=19.4137, |x|=2.91721, |J|=267.943\n",
      "        - Inner Loop: mu=19.4137, norm_dx=0.000934976\n",
      "            (cont): norm_new_f=439.911, dL=0.656759, dF=0.165392, reldL=0.00149237, reldF=0.000375825\n",
      "            Accepted! gain ratio=0.25183  mu * 1.12227 => 21.7875\n",
      "    --- Outer Iter 31: norm_f = 439.911, mu=21.7875, |x|=2.92094, |J|=230.855\n",
      "        - Inner Loop: mu=21.7875, norm_dx=0.00040805\n",
      "            (cont): norm_new_f=442.032, dL=1.40753, dF=-2.12064, reldL=0.00319957, reldF=-0.00482061\n",
      "            Rejected!  mu => mu*nu = 43.575, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=43.575, norm_dx=0.00011802\n",
      "            (cont): norm_new_f=439.922, dL=0.92053, dF=-0.0103703, reldL=0.00209253, reldF=-2.35737e-05\n",
      "            Rejected!  mu => mu*nu = 174.3, nu => 2*nu = 8\n",
      "        - Inner Loop: mu=174.3, norm_dx=8.75887e-06\n",
      "            (cont): norm_new_f=439.477, dL=0.310421, dF=0.434333, reldL=0.000705643, reldF=0.000987319\n",
      "            Accepted! gain ratio=1.39918  mu * 0.333333 => 58.1\n",
      "    --- Outer Iter 32: norm_f = 439.477, mu=58.1, |x|=2.92112, |J|=253.926\n",
      "        - Inner Loop: mu=58.1, norm_dx=1.08758e-05\n",
      "            (cont): norm_new_f=439.331, dL=0.13707, dF=0.146481, reldL=0.000311893, reldF=0.000333308\n",
      "            Accepted! gain ratio=1.06866  mu * 0.333333 => 19.3667\n",
      "    --- Outer Iter 33: norm_f = 439.331, mu=19.3667, |x|=2.92104, |J|=276.992\n",
      "        - Inner Loop: mu=19.3667, norm_dx=0.00027269\n",
      "            (cont): norm_new_f=439.229, dL=0.213563, dF=0.101246, reldL=0.000486111, reldF=0.000230456\n",
      "            Accepted! gain ratio=0.474081  mu * 1.00014 => 19.3694\n",
      "    --- Outer Iter 34: norm_f = 439.229, mu=19.3694, |x|=2.92229, |J|=253.165\n",
      "        - Inner Loop: mu=19.3694, norm_dx=0.000127176\n",
      "            (cont): norm_new_f=439.982, dL=0.473574, dF=-0.752607, reldL=0.00107819, reldF=-0.00171347\n",
      "            Rejected!  mu => mu*nu = 38.7387, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=38.7387, norm_dx=3.78867e-05\n",
      "            (cont): norm_new_f=439.301, dL=0.312058, dF=-0.0714881, reldL=0.000710466, reldF=-0.000162758\n",
      "            Rejected!  mu => mu*nu = 154.955, nu => 2*nu = 8\n",
      "        - Inner Loop: mu=154.955, norm_dx=2.94044e-06\n",
      "            (cont): norm_new_f=439.093, dL=0.108602, dF=0.136294, reldL=0.000247256, reldF=0.000310303\n",
      "            Accepted! gain ratio=1.25499  mu * 0.333333 => 51.6517\n",
      "    --- Outer Iter 35: norm_f = 439.093, mu=51.6517, |x|=2.92267, |J|=270.518\n",
      "        - Inner Loop: mu=51.6517, norm_dx=4.04036e-06\n",
      "            (cont): norm_new_f=439.049, dL=0.0313524, dF=0.044587, reldL=7.14026e-05, reldF=0.000101543\n",
      "            Accepted! gain ratio=1.42213  mu * 0.333333 => 17.2172\n",
      "    --- Outer Iter 36: norm_f = 439.049, mu=17.2172, |x|=2.92308, |J|=277.647\n",
      "        - Inner Loop: mu=17.2172, norm_dx=9.05697e-05\n",
      "            (cont): norm_new_f=438.995, dL=0.0597676, dF=0.0537429, reldL=0.00013613, reldF=0.000122408\n",
      "            Accepted! gain ratio=0.899197  mu * 0.491078 => 8.455\n",
      "    --- Outer Iter 37: norm_f = 438.995, mu=8.455, |x|=2.92443, |J|=266.351\n",
      "        - Inner Loop: mu=8.455, norm_dx=0.00010186\n",
      "            (cont): norm_new_f=439.442, dL=0.154612, dF=-0.446773, reldL=0.000352196, reldF=-0.00101772\n",
      "            Rejected!  mu => mu*nu = 16.91, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=16.91, norm_dx=3.22811e-05\n",
      "            (cont): norm_new_f=439.143, dL=0.107451, dF=-0.148432, reldL=0.000244767, reldF=-0.000338118\n",
      "            Rejected!  mu => mu*nu = 67.64, nu => 2*nu = 8\n",
      "        - Inner Loop: mu=67.64, norm_dx=2.77282e-06\n",
      "            (cont): norm_new_f=438.969, dL=0.0429126, dF=0.0254165, reldL=9.77519e-05, reldF=5.7897e-05\n",
      "    Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 0.0001\n",
      "  _objfn = 877.99 (920 data params - 32 (approx) model params = expected mean of 888; p-value = 0.588076)\n",
      "  Completed in 64.9s\n",
      "  Iteration 1 took 64.9s\n",
      "  \n",
      "--- Iterative GST: Iter 2 of 2  168 circuits ---: \n",
      "  MapLayout: 1 processors divided into 1 x 1 (= 1) grid along circuit and parameter directions.\n",
      "     8 atoms, parameter block size limits (None,)\n",
      "  *** Distributing 8 atoms to 1 atom-processing groups (1 cores) ***\n",
      "      More atom-processors than hosts: each host gets ~1 atom-processors\n",
      "      Atom-processors already occupy a single node, dividing atom-processor into 1 param-processors.\n",
      "  *** Divided 1-host atom-processor (~1 procs) into 1 param-processing groups ***\n",
      "  --- TimeDependentPoissonPicLogLFunction GST ---\n",
      "    --- Outer Iter 0: norm_f = 873.935, mu=1, |x|=2.92443, |J|=316.589\n",
      "        - Inner Loop: mu=71.329, norm_dx=0.000511043\n",
      "            (cont): norm_new_f=871.645, dL=1.94724, dF=2.2898, reldL=0.00222813, reldF=0.0026201\n",
      "            Accepted! gain ratio=1.17592  mu * 0.333333 => 23.7763\n",
      "    --- Outer Iter 1: norm_f = 871.645, mu=23.7763, |x|=2.91513, |J|=279.853\n",
      "        - Inner Loop: mu=23.7763, norm_dx=0.0033612\n",
      "            (cont): norm_new_f=870.886, dL=2.39524, dF=0.759757, reldL=0.00274795, reldF=0.000871636\n",
      "            Accepted! gain ratio=0.317195  mu * 1.04887 => 24.9383\n",
      "    --- Outer Iter 2: norm_f = 870.886, mu=24.9383, |x|=2.89746, |J|=513.822\n",
      "        - Inner Loop: mu=24.9383, norm_dx=0.000214322\n",
      "            (cont): norm_new_f=872.646, dL=6.20726, dF=-1.7608, reldL=0.00712753, reldF=-0.00202185\n",
      "            Rejected!  mu => mu*nu = 49.8766, nu => 2*nu = 4\n",
      "        - Inner Loop: mu=49.8766, norm_dx=7.46315e-05\n",
      "            (cont): norm_new_f=870.551, dL=4.7519, dF=0.3343, reldL=0.0054564, reldF=0.000383863\n",
      "            Accepted! gain ratio=0.0703508  mu * 1.6345 => 81.5233\n",
      "    --- Outer Iter 3: norm_f = 870.551, mu=81.5233, |x|=2.89086, |J|=286.137\n",
      "        - Inner Loop: mu=81.5233, norm_dx=0.000119945\n",
      "            (cont): norm_new_f=870.267, dL=2.28393, dF=0.283909, reldL=0.00262355, reldF=0.000326125\n",
      "            Accepted! gain ratio=0.124307  mu * 1.42422 => 116.107\n",
      "    --- Outer Iter 4: norm_f = 870.267, mu=116.107, |x|=2.89107, |J|=3462.56\n",
      "        - Inner Loop: mu=116.107, norm_dx=5.75778e-06\n",
      "            (cont): norm_new_f=868.803, dL=1.76057, dF=1.46469, reldL=0.00202302, reldF=0.00168303\n",
      "            Accepted! gain ratio=0.83194  mu * 0.707404 => 82.1346\n",
      "    --- Outer Iter 5: norm_f = 868.803, mu=82.1346, |x|=2.88919, |J|=441.327\n",
      "        - Inner Loop: mu=82.1346, norm_dx=1.45812e-05\n",
      "            (cont): norm_new_f=868.666, dL=0.197728, dF=0.136299, reldL=0.000227587, reldF=0.000156881\n",
      "            Accepted! gain ratio=0.689324  mu * 0.945711 => 77.6756\n",
      "    --- Outer Iter 6: norm_f = 868.666, mu=77.6756, |x|=2.88799, |J|=365.993\n",
      "        - Inner Loop: mu=77.6756, norm_dx=1.15541e-05\n",
      "            (cont): norm_new_f=868.592, dL=0.050525, dF=0.0742624, reldL=5.81639e-05, reldF=8.54901e-05\n",
      "    Least squares message = Both actual and predicted relative reductions in the sum of squares are at most 0.0001\n",
      "  _objfn = 1737.33 (1680 data params - 32 (approx) model params = expected mean of 1648; p-value = 0.0617401)\n",
      "  Completed in 23.6s\n",
      "  Iteration 2 took 23.7s\n",
      "  \n",
      "  Last iteration:\n",
      "  Final optimization took 0.0s\n",
      "  \n",
      "Iterative GST Total Time: 88.7s\n"
     ]
    }
   ],
   "source": [
    "target_model = smq1Q_XYI.target_model(\"full TP\", simulator=\"map\") # TP-constraints on the non-Gi gates\n",
    "target_model[idle_gate_label] = MyTimeDependentIdle(0.0)\n",
    "target_model.sim = pygsti.forwardsims.MapForwardSimulator(max_cache_size=0)\n",
    "\n",
    "builders = pygsti.protocols.GSTObjFnBuilders([pygsti.objectivefns.TimeDependentPoissonPicLogLFunction.builder()],[])\n",
    "custom_opt = {'tol': 1e-4, 'damping_mode': 'JTJ', 'damping_clip': (1.0, 1000.0)} # tweak optimizer parameters for better performance (expert-level)\n",
    "gst = pygsti.protocols.GateSetTomography(target_model, gaugeopt_suite=None,\n",
    "                                         objfn_builders=builders, optimizer=custom_opt, verbosity=4)\n",
    "data = pygsti.protocols.ProtocolData(edesign, ds)\n",
    "results = gst.run(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the (non-gauge-optimizeed) best-fit model from `results`, and see what depolarization \"acceleration\" was found.  We find that the value is reasonably close to the value of 1.0 that we used to generate the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-dependent idle parameters =  [0.989367]\n"
     ]
    }
   ],
   "source": [
    "final_mdl = results.estimates['GateSetTomography'].models['final iteration estimate']\n",
    "print(\"Time-dependent idle parameters = \",final_mdl[idle_gate_label].to_vector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective function at data-generating model =  880.9619775626477\n",
      "Objective function at best-fit (GST) model (should be lower) =  868.6663676923431\n"
     ]
    }
   ],
   "source": [
    "# Check that GST model fits the data *better* than the data-generating model\n",
    "builder = pygsti.objectivefns.TimeDependentPoissonPicLogLFunction.builder()\n",
    "objfn = builder.build(mdl_datagen, data.dataset, list(data.dataset.keys()))\n",
    "print(\"Objective function at data-generating model = \",objfn.fn())\n",
    "\n",
    "objfn2 = builder.build(final_mdl, data.dataset, list(data.dataset.keys()))\n",
    "print(\"Objective function at best-fit (GST) model (should be lower) = \",objfn2.fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "random_pygsti_debugging",
   "language": "python",
   "name": "random_pygsti_debugging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
