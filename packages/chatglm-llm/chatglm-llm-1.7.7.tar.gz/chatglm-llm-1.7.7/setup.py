
from setuptools import setup, find_packages


setup(name='chatglm-llm',
    version='1.7.7',
    description='chatglm llm',
    url='https://github.com/xxx',
    author='auth',
    author_email='xxx@gmail.com',
    license='MIT',
    include_package_data=True,
    zip_safe=False,
    packages=find_packages(),
    extras_require={
        "all": [
            'sentence_transformers==2.2.2',
            'tensorboard',
            "protobuf",
            'gptcache==0.1.42',
            "fschat==0.2.2",
            "cpm_kernels",
            "mdtex2html",
            "sse-starlette",
            "sentencepiece",
            'loguru',
            "accelerate",
            "scikit-learn",
            "aiohttp",
            'pydantic==1.10.9',
            'fastapi==0.104.1',
            'requests',
            'torch',    
            'termcolor',
            'uvicorn',
            'modelscope',
            'sse_starlette',
            'transformers',
            'langchain-experimental',
        ],
    },
    install_requires=[
        "aiohttp",
        "sse-starlette",
        'requests',
        'termcolor',
        'tqdm',
        'gptcache',
        'numpy',
        'uvicorn',
        'sse_starlette',
        'pypdf',
        "scikit-learn",
        'gptcache==0.1.42',
        'sqlalchemy==2.0.22',
        'pydantic==1.10.9',
        'langchain==0.0.325',
        'fastapi==0.104.1',
        'unstructured',
        'loguru',
        'langchain-experimental',
        ],
    entry_points={
        'console_scripts': [
            'chatglm-web=chatglm_src.cmd:main',
        ]
    },

)
