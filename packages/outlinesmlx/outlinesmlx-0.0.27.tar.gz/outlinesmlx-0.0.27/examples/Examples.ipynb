{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4791713a-e11e-47c8-9c8f-2fc8a0965eec",
   "metadata": {},
   "source": [
    "# Guided generation from a Regex Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc405bd-53cf-4488-a8b3-72d8e3038767",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9370c731991452c9a454340843b1bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:  What is the IP address of the Google DNS servers? \n",
      "\n",
      " Result, unguided: \n",
      " 2. What is the country/region where the Google DNS servers are located? 3. According to this page, can I use Google custom domains\n",
      "\n",
      " Result, guided: \n",
      " 2.1.2.168\n"
     ]
    }
   ],
   "source": [
    "import outlinesmlx as outlines\n",
    "\n",
    "model = outlines.models.mlx(\"TinyLlama/TinyLlama-1.1B-Chat-v0.6\")\n",
    "\n",
    "prompt = \"What is the IP address of the Google DNS servers? \"\n",
    "\n",
    "generator = outlines.generate.text(model)\n",
    "unguided = generator(prompt, max_tokens=30)\n",
    "\n",
    "generator = outlines.generate.regex(\n",
    "    model,\n",
    "    r\"((25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\",\n",
    ")\n",
    "guided = generator(prompt, max_tokens=30)\n",
    "\n",
    "print(\"Prompt: \",prompt)\n",
    "\n",
    "print(\"\\n Result, unguided: \\n\",unguided)\n",
    "# What is the IP address of the Google DNS servers?\n",
    "#\n",
    "# Passive DNS servers are at DNS servers that are private.\n",
    "# In other words, both IP servers are private. The database\n",
    "# does not contain Chelsea Manning\n",
    "\n",
    "print(\"\\n Result, guided: \\n\",guided)\n",
    "# What is the IP address of the Google DNS servers?\n",
    "# 2.2.6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c38c5b-7073-40d1-9fb7-f2e7eec7de2d",
   "metadata": {},
   "source": [
    "# Guided generation from a Pydantic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "305a9477-d265-4bb7-ba21-ce3aeb340ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character(name='Alice', age=35, armor=<Armor.leather: 'leather'>, weapon=<Weapon.axe: 'axe'>, strength=90)\n",
      "Character(name='Sophia', age=25, armor=<Armor.leather: 'leather'>, weapon=<Weapon.sword: 'sword'>, strength=30)\n"
     ]
    }
   ],
   "source": [
    "import outlinesmlx as outlines\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, constr\n",
    "\n",
    "\n",
    "class Weapon(str, Enum):\n",
    "    sword = \"sword\"\n",
    "    axe = \"axe\"\n",
    "    mace = \"mace\"\n",
    "    spear = \"spear\"\n",
    "    bow = \"bow\"\n",
    "    crossbow = \"crossbow\"\n",
    "\n",
    "\n",
    "class Armor(str, Enum):\n",
    "    leather = \"leather\"\n",
    "    chainmail = \"chainmail\"\n",
    "    plate = \"plate\"\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: constr(max_length=10)\n",
    "    age: int\n",
    "    armor: Armor\n",
    "    weapon: Weapon\n",
    "    strength: int\n",
    "\n",
    "model = outlines.models.mlx(\"TinyLlama/TinyLlama-1.1B-Chat-v0.6\")\n",
    "# Construct guided sequence generator\n",
    "generator = outlines.generate.json(model, Character, max_tokens=100)\n",
    "\n",
    "# Draw a sample\n",
    "character = generator(\"Give me a character description\")\n",
    "\n",
    "print(repr(character))\n",
    "\n",
    "character = generator(\"Give me an interesting character description\")\n",
    "\n",
    "print(repr(character))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf1b78-79bf-4549-bef1-28b3b207bf23",
   "metadata": {},
   "source": [
    "# Guided generation from a JSON schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19baf501-78fd-4fee-a481-d9c5312c9e06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c270a10f5013458a85a097c6b8f61a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1446 column 5 (char 4705)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m outlines\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mmlx(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/phi-2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m generator \u001b[38;5;241m=\u001b[39m outlines\u001b[38;5;241m.\u001b[39mgenerate\u001b[38;5;241m.\u001b[39mjson(model, schema)\n\u001b[0;32m---> 42\u001b[0m character \u001b[38;5;241m=\u001b[39m generator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGive me a character description\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(character)\n",
      "File \u001b[0;32m~/Documents/CARGOHUB/outlines-mlx/outlinesmlx/generate/api.py:245\u001b[0m, in \u001b[0;36mSequenceGenerator.__call__\u001b[0;34m(self, prompts, max_tokens, stop_at, kv_cache)\u001b[0m\n\u001b[1;32m    240\u001b[0m generated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_token_ids)\n\u001b[1;32m    241\u001b[0m stripped \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip_stop_sequences(sequence, stop_sequences)\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sequence \u001b[38;5;129;01min\u001b[39;00m generated\n\u001b[1;32m    244\u001b[0m ]\n\u001b[0;32m--> 245\u001b[0m formatted \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_sequence(sequence) \u001b[38;5;28;01mfor\u001b[39;00m sequence \u001b[38;5;129;01min\u001b[39;00m stripped]\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# We reshape the output to (sample_size, batch_size)\u001b[39;00m\n\u001b[1;32m    248\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/CARGOHUB/outlines-mlx/outlinesmlx/generate/api.py:245\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    240\u001b[0m generated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_token_ids)\n\u001b[1;32m    241\u001b[0m stripped \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip_stop_sequences(sequence, stop_sequences)\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sequence \u001b[38;5;129;01min\u001b[39;00m generated\n\u001b[1;32m    244\u001b[0m ]\n\u001b[0;32m--> 245\u001b[0m formatted \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_sequence(sequence) \u001b[38;5;28;01mfor\u001b[39;00m sequence \u001b[38;5;129;01min\u001b[39;00m stripped]\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# We reshape the output to (sample_size, batch_size)\u001b[39;00m\n\u001b[1;32m    248\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/CARGOHUB/outlines-mlx/outlinesmlx/generate/json.py:34\u001b[0m, in \u001b[0;36mjson.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     32\u001b[0m     regex_str \u001b[38;5;241m=\u001b[39m build_regex_from_object(schema)\n\u001b[1;32m     33\u001b[0m     generator \u001b[38;5;241m=\u001b[39m regex(model, regex_str, max_tokens, sampler)\n\u001b[0;32m---> 34\u001b[0m     generator\u001b[38;5;241m.\u001b[39mformat_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: pyjson\u001b[38;5;241m.\u001b[39mloads(x)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot parse schema \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema_object\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. The schema must be either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma Pydantic object, a function or a string that contains the JSON \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSchema specification\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1446 column 5 (char 4705)"
     ]
    }
   ],
   "source": [
    "import outlinesmlx as outlines\n",
    "\n",
    "schema = '''{\n",
    "    \"title\": \"Character\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\n",
    "            \"title\": \"Name\",\n",
    "            \"maxLength\": 10,\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"age\": {\n",
    "            \"title\": \"Age\",\n",
    "            \"type\": \"integer\"\n",
    "        },\n",
    "        \"armor\": {\"$ref\": \"#/definitions/Armor\"},\n",
    "        \"weapon\": {\"$ref\": \"#/definitions/Weapon\"},\n",
    "        \"strength\": {\n",
    "            \"title\": \"Strength\",\n",
    "            \"type\": \"integer\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\", \"armor\", \"weapon\", \"strength\"],\n",
    "    \"definitions\": {\n",
    "        \"Armor\": {\n",
    "            \"title\": \"Armor\",\n",
    "            \"description\": \"An enumeration.\",\n",
    "            \"enum\": [\"leather\", \"chainmail\", \"plate\"],\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"Weapon\": {\n",
    "            \"title\": \"Weapon\",\n",
    "            \"description\": \"An enumeration.\",\n",
    "            \"enum\": [\"sword\", \"axe\", \"mace\", \"spear\", \"bow\", \"crossbow\"],\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    }\n",
    "}'''\n",
    "\n",
    "model = outlines.models.mlx(\"microsoft/phi-2\")\n",
    "generator = outlines.generate.json(model, schema)\n",
    "character = generator(\"Give me a character description\", max_tokens=2048)\n",
    "print(character)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd6ab0-7a31-4710-a9f5-b11cab693eb2",
   "metadata": {},
   "source": [
    "# Context free grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a6735a-bd2e-4b2e-91ae-7a892ddd3b13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179f9b5a56534fcfb62495333725252d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4-2.5-2.3-1.5-1.7-2.7-1.9-2.1-1.6-0.9-2.3-1.7-1.3-2.0-2.0-2.1-2.1-0.0-2.8-2.8-3.1-4.2-2.3-2.6-1.9-1.4-1.9-1.5-1.7-1.5-2.2-1.8-1.1-0.9-2.6-2.8-3.0-1.6-0.3-2.1-1.7-1.4-1.8-2.0-2.2-2.2-0.0-2.9-2.4-3.3-2.7-1.0-2.6-0.3-1.1-2.0-1.9-2.5-0.8-1.9-2.0-0.1-2.1-2.0-2.1-2.4+2.7+3.3-4.2+1.3+0.6-0.4-0.0-0.1-0.2-2.\n"
     ]
    }
   ],
   "source": [
    "import outlinesmlx as outlines\n",
    "\n",
    "arithmetic_grammar = \"\"\"\n",
    "    ?start: expression\n",
    "\n",
    "    ?expression: term ((\"+\" | \"-\") term)*\n",
    "\n",
    "    ?term: factor ((\"*\" | \"/\") factor)*\n",
    "\n",
    "    ?factor: NUMBER\n",
    "           | \"-\" factor\n",
    "           | \"(\" expression \")\"\n",
    "\n",
    "    %import common.NUMBER\n",
    "\"\"\"\n",
    "\n",
    "model = outlines.models.mlx(\"microsoft/phi-2\")\n",
    "generator = outlines.generate.cfg(model, arithmetic_grammar)\n",
    "sequence = generator(\"Alice had 4 apples and Bob ate 2. Write an expression for Alice's apples:\",max_tokens=300)\n",
    "\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3412d8-1a94-49af-adb7-8c32958b4bdc",
   "metadata": {},
   "source": [
    "# Open Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597d8570-18b1-41c5-9418-bc6135481e41",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752d7780c52149749abfc9235425aff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: {'a': 8, 'b': 4}\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "import outlinesmlx as outlines\n",
    "\n",
    "\n",
    "def add(a: int, b: int):\n",
    "    return a + b\n",
    "\n",
    "model = outlines.models.mlx(\"TinyLlama/TinyLlama-1.1B-Chat-v0.6\")\n",
    "generator = outlines.generate.json(model, add)\n",
    "result = generator(\"Return json with two integers named a and b respectively. a is odd and b even.\")\n",
    "\n",
    "print(\"result:\",result)\n",
    "print(add(**result))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
