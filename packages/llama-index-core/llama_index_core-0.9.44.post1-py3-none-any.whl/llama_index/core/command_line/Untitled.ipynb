{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec9dcae-8901-4eba-98f2-5bb59d7cc9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.command_line.upgrade import upgrade_nb_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9dad71-7e4f-400e-b598-60abeda50231",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/nerdai/Projects/migration/llama_index/docs/examples/agent/Chatbot_SEC.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d587cdf-5285-4b3f-aea2-c181c54a3aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================\n",
      "line: from llama_hub.file.unstructured.base import UnstructuredReader\n",
      "\n",
      "\n",
      "imported modules: ['from llama_hub.file.unstructured.base import UnstructuredReader\\n', ['UnstructuredReader']]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================\n",
      "line: from llama_index import VectorStoreIndex, ServiceContext, StorageContext\n",
      "\n",
      "\n",
      "imported modules: ['from llama_index import VectorStoreIndex, ServiceContext, StorageContext\\n', ['VectorStoreIndex', 'ServiceContext', 'StorageContext']]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================\n",
      "line: from llama_index import load_index_from_storage\n",
      "\n",
      "\n",
      "imported modules: ['from llama_index import load_index_from_storage\\n', ['load_index_from_storage']]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================\n",
      "line: from llama_index.tools import QueryEngineTool, ToolMetadata\n",
      "\n",
      "\n",
      "imported modules: ['from llama_index.tools import QueryEngineTool, ToolMetadata\\n', ['QueryEngineTool', 'ToolMetadata']]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================\n",
      "line: from llama_index.query_engine import SubQuestionQueryEngine\n",
      "\n",
      "\n",
      "imported modules: ['from llama_index.query_engine import SubQuestionQueryEngine\\n', ['SubQuestionQueryEngine']]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==================\n",
      "line: from llama_index.agent import OpenAIAgent\n",
      "\n",
      "\n",
      "imported modules: ['from llama_index.agent import OpenAIAgent\\n', ['OpenAIAgent']]\n",
      "\n",
      "\n",
      "new_installs: ['%pip install llama-index-readers-file', '%pip install llama-index-agent-openai']\n"
     ]
    }
   ],
   "source": [
    "upgrade_nb_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b1d7ea-19e1-4706-8880-797ebc806448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-core",
   "language": "python",
   "name": "llama-index-core"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
